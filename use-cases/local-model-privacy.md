# Use Case: Privacy-Focused Local Model Workflow

## Scenario

A user wants local inference for sensitive tasks.

## Setup

- Install Ollama or LM Studio
- Configure provider in API Keys

## Workflow

1. Connect local provider in settings.
2. Select local model from `/` selector.
3. Attach files and run private analysis prompts.
4. Validate outputs and adjust model choice by task.

## Outcome

Improved privacy posture while keeping Alter workflow speed.

## Docs

- https://alterhq.com/docs#locally-using-ollama-or-lm-studio
- https://alterhq.com/docs#using-your-api-key
